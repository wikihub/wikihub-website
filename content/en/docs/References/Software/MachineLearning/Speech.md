---
title: "Speech"
linkTitle: "Speech"
date: 2021-05-06
weight: 50
description: News and information about Speech synthesis and voice analysis
---

# Datasets
* [LJ Speech Dataset](https://keithito.com/LJ-Speech-Dataset/)

# Audio Players
* [sox](http://sox.sourceforge.net/)

# Speech Toolkits
* [espnet](https://github.com/espnet/espnet)
* [Merlin](https://github.com/CSTR-Edinburgh/merlin)
* [Silero Models](https://github.com/snakers4/silero-models)
* [aeneas: automagically synchronize audio and text (aka forced alignment)](https://www.readbeyond.it/aeneas/)
* [awesome-speech-recognition-speech-synthesis-papers](https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers)

## Speech Synthesis
* [Resemble.ai](https://www.resemble.ai/)
* [Mozilla TTS](https://github.com/mozilla/TTS/)
* [W3 Speak](https://www.w3.org/TR/speech-synthesis/#edef_speak)
* [Text to speech: SSML by Google](https://cloud.google.com/text-to-speech/docs/ssml)
* [tacotron](https://github.com/keithito/tacotron)
* [coqui-ai TTS](https://github.com/coqui-ai/TTS)
* [Coqui: Freeing Speech](https://coqui.ai/)
* [TensorFlowTTS](https://github.com/TensorSpeech/TensorFlowTTS)
* [gTTS](https://gtts.readthedocs.io/en/latest/)
* [larynx](https://github.com/rhasspy/larynx)
* [Parallel WaveGAN](https://kan-bayashi.github.io/ParallelWaveGAN/)
* [MockingBird](https://github.com/babysor/MockingBird)

### Persian
* [Lilak project](http://lilak-project.com)
* [Tihu](https://github.com/tihu-nlp/tihu)
* [AlisterTA: Persian-text-to-speech](https://github.com/AlisterTA/Persian-text-to-speech)
* [Persian pronounciation](https://github.com/mehdihosseinimoghadam/Persian-Pronounciation)
* [Persian_Tacotron2](https://github.com/majidAdibian77/persian_tacotron)
* [Ariana](http://www.nevisasoft.com/other-products/ariana)
* [Gata](https://www.msgata.com/Products/TextToSpeech)
* [Amer Andish](https://amerandish.com/)

## Voice assistants
* [leon](https://github.com/leon-ai/leon)
* [rhasspy](https://github.com/rhasspy/rhasspy)
* [Kalliope Project](https://kalliope-project.github.io/)
* [Dragonfire](https://github.com/DragonComputer/Dragonfire)

## NVIDIA
* [NeMo - Text to Speech](https://ngc.nvidia.com/catalog/collections/nvidia:nemo_tts)
* [NVIDIA Nemo](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/tts/intro.html)
* [NVIDIA Nemo example scripts](https://github.com/NVIDIA/NeMo/tree/main/examples)
* [Nemo TTS models](https://ngc.nvidia.com/catalog/models/nvidia:nemottsmodels)
* [NVIDIA Nemo Jupyter Notebooks](https://github.com/NVIDIA/NeMo#tutorials)
* [I AM AI](https://www.youtube.com/playlist?list=PLZHnYvH1qtObE_PjzaAFqS_CpmumGx5cW)
* [Voice swap sample](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/VoiceSwapSample.ipynb)
* [Generate Natural Sounding Speech from Text in Real-Time](https://developer.nvidia.com/blog/generate-natural-sounding-speech-from-text-in-real-time/)
* [All the Feels: NVIDIA Shares Expressive Speech Synthesis Research at Interspeech](https://www.youtube.com/watch?v=RknIx6XmffA)
* [Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis](https://nv-adlr.github.io/Flowtron)

# Text to Speech
* [NVIDIA Blog: Speech Synthesis](https://developer.nvidia.com/blog/tag/speech-synthesis/)
* [Building a Text-to-Speech Service that Sounds like You, Using NVIDIA NGC and NVIDIA A100 GPUs](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32117/)
* [All the Feels: NVIDIA Shares Expressive Speech Synthesis Research at Interspeech](https://blogs.nvidia.com/blog/2021/08/31/conversational-ai-research-speech-synthesis-interspeech/)
* [Text to speech: Isaac SDK](https://docs.nvidia.com/isaac/archive/2020.1/packages/audio/doc/text_to_speech.html)


# Conversation

* [alexar](https://github.com/jhudsl/alexar)
