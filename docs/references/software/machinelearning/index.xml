<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>WIKIHUB â€“ Machine Learning</title>
    <link>https://wikihub.github.io/docs/references/software/machinelearning/</link>
    <description>Recent Hugo news from gohugo.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 22 Feb 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://wikihub.github.io/img/hugo.png</url>
      <title>GoHugo.io</title>
      <link>https://wikihub.github.io/docs/references/software/machinelearning/</link>
    </image>
    
	  <atom:link href="https://wikihub.github.io/docs/references/software/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Machine Vision</title>
      <link>https://wikihub.github.io/docs/references/software/machinelearning/machinevision/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wikihub.github.io/docs/references/software/machinelearning/machinevision/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://opendatacam.github.io/opendatacam/&#34;&gt;opendatacam&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Speech</title>
      <link>https://wikihub.github.io/docs/references/software/machinelearning/speech/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wikihub.github.io/docs/references/software/machinelearning/speech/</guid>
      <description>
        
        
        &lt;h1 id=&#34;audio-players&#34;&gt;Audio Players&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://sox.sourceforge.net/&#34;&gt;sox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;speech-toolkits&#34;&gt;Speech Toolkits&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/espnet/espnet&#34;&gt;espnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34;&gt;Merlin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.readbeyond.it/aeneas/&#34;&gt;aeneas: automagically synchronize audio and text (aka forced alignment)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;speech-synthesis&#34;&gt;Speech Synthesis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.resemble.ai/&#34;&gt;Resemble.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/mozilla/TTS/&#34;&gt;Mozilla TTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.w3.org/TR/speech-synthesis/#edef_speak&#34;&gt;W3 Speak&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/text-to-speech/docs/ssml&#34;&gt;Text to speech: SSML by Google&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34;&gt;tacotron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;coqui-ai TTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coqui.ai/&#34;&gt;Coqui: Freeing Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/TensorSpeech/TensorFlowTTS&#34;&gt;TensorFlowTTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gtts.readthedocs.io/en/latest/&#34;&gt;gTTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;voice-assistants&#34;&gt;Voice assistants&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/leon-ai/leon&#34;&gt;leon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rhasspy/rhasspy&#34;&gt;rhasspy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/DragonComputer/Dragonfire&#34;&gt;Dragonfire&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;nvidia-nemo&#34;&gt;NVIDIA Nemo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ngc.nvidia.com/catalog/collections/nvidia:nemo_tts&#34;&gt;NeMo - Text to Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/tts/intro.html&#34;&gt;NVIDIA Nemo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/NeMo/tree/main/examples&#34;&gt;NVIDIA Nemo example scripts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ngc.nvidia.com/catalog/models/nvidia:nemottsmodels&#34;&gt;Nemo TTS models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/NeMo#tutorials&#34;&gt;NVIDIA Nemo Jupyter Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZHnYvH1qtObE_PjzaAFqS_CpmumGx5cW&#34;&gt;I AM AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/NeMo/blob/stable/tutorials/VoiceSwapSample.ipynb&#34;&gt;Voice swap sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/generate-natural-sounding-speech-from-text-in-real-time/&#34;&gt;Generate Natural Sounding Speech from Text in Real-Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=RknIx6XmffA&#34;&gt;All the Feels: NVIDIA Shares Expressive Speech Synthesis Research at Interspeech&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;text-to-speech&#34;&gt;Text to Speech&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/tag/speech-synthesis/&#34;&gt;NVIDIA Blog: Speech Synthesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32117/&#34;&gt;Building a Text-to-Speech Service that Sounds like You, Using NVIDIA NGC and NVIDIA A100 GPUs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.nvidia.com/blog/2021/08/31/conversational-ai-research-speech-synthesis-interspeech/&#34;&gt;All the Feels: NVIDIA Shares Expressive Speech Synthesis Research at Interspeech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/isaac/archive/2020.1/packages/audio/doc/text_to_speech.html&#34;&gt;Text to speech: Isaac SDK&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;conversation&#34;&gt;Conversation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jhudsl/alexar&#34;&gt;alexar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>